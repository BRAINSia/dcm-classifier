{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Running the Classifier\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3cc3a861cf61ef55"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setting up the classes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "625581a797ec991e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!pip install dcm-classifier0.6.0rc7"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "327d9c5468193f5d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory: /home/cavriley/programs/dcm-classifier/tests/testing_data/anonymized_testing_data/anonymized_data contains 16 DICOM sub-volumes\n"
     ]
    },
    {
     "ename": "InvalidArgument",
     "evalue": "[ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Got invalid dimensions for input: float_input for the following indices\n index: 1 Got: 48 Expected: 29\n Please fix either the inputs or the model.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInvalidArgument\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 18\u001B[0m\n\u001B[1;32m     13\u001B[0m inferer \u001B[38;5;241m=\u001B[39m ImageTypeClassifierBase(classification_model_filename\u001B[38;5;241m=\u001B[39mmodel\u001B[38;5;241m.\u001B[39mas_posix())\n\u001B[1;32m     14\u001B[0m study \u001B[38;5;241m=\u001B[39m ProcessOneDicomStudyToVolumesMappingBase(\n\u001B[1;32m     15\u001B[0m     study_directory\u001B[38;5;241m=\u001B[39msession_directory\u001B[38;5;241m.\u001B[39mas_posix(), inferer\u001B[38;5;241m=\u001B[39minferer\n\u001B[1;32m     16\u001B[0m )\n\u001B[0;32m---> 18\u001B[0m \u001B[43mstudy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_inference\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/programs/dcm-classifier/venv/lib/python3.10/site-packages/dcm_classifier/study_processing.py:258\u001B[0m, in \u001B[0;36mProcessOneDicomStudyToVolumesMappingBase.run_inference\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    253\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m (\n\u001B[1;32m    254\u001B[0m     series_number,\n\u001B[1;32m    255\u001B[0m     series_object,\n\u001B[1;32m    256\u001B[0m ) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mseries_dictionary\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m    257\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minferer\u001B[38;5;241m.\u001B[39mset_series(series_object)\n\u001B[0;32m--> 258\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minferer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_inference\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/programs/dcm-classifier/venv/lib/python3.10/site-packages/dcm_classifier/image_type_inference.py:361\u001B[0m, in \u001B[0;36mImageTypeClassifierBase.run_inference\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    358\u001B[0m contrast \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minfer_contrast(feature_dict\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minfo_dict)\n\u001B[1;32m    359\u001B[0m volume\u001B[38;5;241m.\u001B[39mset_has_contrast(contrast)\n\u001B[0;32m--> 361\u001B[0m modality, full_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minfer_modality\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    362\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfeature_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvolume\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_volume_dictionary\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    363\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    364\u001B[0m volume\u001B[38;5;241m.\u001B[39mset_volume_modality(modality)\n\u001B[1;32m    365\u001B[0m volume\u001B[38;5;241m.\u001B[39mset_modality_probabilities(pd\u001B[38;5;241m.\u001B[39mDataFrame(full_outputs, index\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m0\u001B[39m]))\n",
      "File \u001B[0;32m~/programs/dcm-classifier/venv/lib/python3.10/site-packages/dcm_classifier/image_type_inference.py:273\u001B[0m, in \u001B[0;36mImageTypeClassifierBase.infer_modality\u001B[0;34m(self, feature_dict)\u001B[0m\n\u001B[1;32m    270\u001B[0m     full_outputs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGUESS_ONNX\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalidDicomInputs\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    271\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mINVALID\u001B[39m\u001B[38;5;124m\"\u001B[39m, full_outputs\n\u001B[0;32m--> 273\u001B[0m pred_onx_run_output \u001B[38;5;241m=\u001B[39m \u001B[43msess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    274\u001B[0m \u001B[43m    \u001B[49m\u001B[43m[\u001B[49m\u001B[43mlabel_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprob_name\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43minput_name\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumeric_inputs\u001B[49m\u001B[43m}\u001B[49m\n\u001B[1;32m    275\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    276\u001B[0m pred_onx \u001B[38;5;241m=\u001B[39m pred_onx_run_output[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    277\u001B[0m probability_onx \u001B[38;5;241m=\u001B[39m pred_onx_run_output[\u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[0;32m~/programs/dcm-classifier/venv/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:220\u001B[0m, in \u001B[0;36mSession.run\u001B[0;34m(self, output_names, input_feed, run_options)\u001B[0m\n\u001B[1;32m    218\u001B[0m     output_names \u001B[38;5;241m=\u001B[39m [output\u001B[38;5;241m.\u001B[39mname \u001B[38;5;28;01mfor\u001B[39;00m output \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_outputs_meta]\n\u001B[1;32m    219\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 220\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput_names\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_feed\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_options\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    221\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m C\u001B[38;5;241m.\u001B[39mEPFail \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m    222\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_enable_fallback:\n",
      "\u001B[0;31mInvalidArgument\u001B[0m: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Got invalid dimensions for input: float_input for the following indices\n index: 1 Got: 48 Expected: 29\n Please fix either the inputs or the model."
     ]
    }
   ],
   "source": [
    "from dcm_classifier.study_processing import ProcessOneDicomStudyToVolumesMappingBase\n",
    "from dcm_classifier.image_type_inference import ImageTypeClassifierBase\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "current_directory: Path = Path.cwd()\n",
    "root_directory = current_directory.parent\n",
    "\n",
    "session_directory = root_directory / \"tests\" / \"testing_data\" / \"anonymized_testing_data\" / \"anonymized_data\"\n",
    "\n",
    "model = root_directory / \"models\" / \"rf_classifier.onnx\"\n",
    "\n",
    "inferer = ImageTypeClassifierBase(classification_model_filename=model.as_posix())\n",
    "study = ProcessOneDicomStudyToVolumesMappingBase(\n",
    "    study_directory=session_directory.as_posix(), inferer=inferer\n",
    ")\n",
    "\n",
    "study.run_inference()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T20:54:41.250416Z",
     "start_time": "2024-03-12T20:54:41.037909Z"
    }
   },
   "id": "6f60406e6bd8cb36",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Choosing preferred files"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa5ec368dfbd73a3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Saving to Nifti\n",
    "\n",
    "Saving to a nifti file can be done in two ways here, ITK and dcm2niix both provide methods however the ITK method is preferred because of its robustness. For these examples, we are looking for T1W modality and axial acquisition plane images. \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8258caa4e8f6ce9c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Using ITK\n",
    "\n",
    "Once the image is obtained, the image can easily be saved using ITK. ITK is the preferred method for saving the image as it is more robust in the sense that many image types can be handled including .nii.gz and .nrrd files unlike dcm2niix."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "132dae0cc155b33f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import itk\n",
    "\n",
    "for series_number, series in study.series_dictionary.items():\n",
    "    for index, volume in enumerate(series.get_volume_list()):\n",
    "        if volume.get_volume_modality() == \"t1w\" and volume.get_acquisition_plane() == \"ax\":\n",
    "            volume_image = volume.get_itk_image()\n",
    "            itk.imwrite(volume_image, \"tutorial_itk_image.nii.gz\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc7624cd311e63ec"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Using dcm2niix\n",
    "\n",
    "The dcm2niix method is also available, however it is not as robust as the ITK method. The dcm2niix method is used to convert the DICOM files to a nifti  and does not support other file types such as .nrrd. Also, the dcm2niix method is an external method and requires the dcm2niix software to be installed on the system."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a234e78bf447bb18"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from subprocess import run\n",
    "\n",
    "def create_nifti_file(\n",
    "    dcm2niix_path: str,\n",
    "    subject: str,\n",
    "    session: str,\n",
    "    modality: str,\n",
    "    plane: str,\n",
    "    output_dir: str,\n",
    "    dcm_dir: str,\n",
    "    desc: str = None,\n",
    ") -> None:\n",
    "    run_num = 1\n",
    "    if desc is not None:\n",
    "        fname = (\n",
    "            f\"{subject}_{session}_run-00{run_num}_acq-{plane}_desc-{desc}_{modality}\"\n",
    "        )\n",
    "    else:\n",
    "        fname = f\"{subject}_{session}_run-00{run_num}_acq-{plane}_{modality}\"\n",
    "    while Path(f\"{output_dir}/{fname}.nii.gz\").exists():\n",
    "        fname = fname.replace(f\"run-00{run_num}\", f\"run-00{run_num+1}\")\n",
    "        run_num += 1\n",
    "    run(\n",
    "        [dcm2niix_path, \"-o\", output_dir, \"-f\", fname, \"-z\", \"y\", dcm_dir]\n",
    "    ) \n",
    "    print(f\"{dcm2niix_path} -o {output_dir} -f {fname} -n -z y {dcm_dir}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aafd9e0c5aa9c2da"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The DICOM files are moved to a temporary directory because the files should all be located within the same directory for dcm2niix to work."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae0313c96f431405"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import shutil\n",
    "    \n",
    "dcm2niix_path = \"FILL IN\"\n",
    "\n",
    "sub = \"sub-01-test\"\n",
    "ses = \"ses-01-test\"\n",
    "\n",
    "final_dir_path = \"FILL IN\"\"\n",
    "\n",
    "for series_number, series in study.series_dictionary.items():\n",
    "    for index, volume in enumerate(series.get_volume_list()):\n",
    "        if volume.get_volume_modality() == \"t1w\" and volume.get_acquisition_plane() == \"ax\":\n",
    "            temp_dir = tempfile.mkdtemp()\n",
    "            file_list = volume.get_one_volume_dcm_filenames()\n",
    "            for file in file_list:\n",
    "                shutil.copy(file, temp_dir)\n",
    "            create_nifti_file(\n",
    "                dcm2niix_path=dcm2niix_path,\n",
    "                subject=sub,\n",
    "                session=ses,\n",
    "                modality=volume.get_volume_modality(),\n",
    "                plane=volume.get_acquisition_plane(),\n",
    "                output_dir=final_dir_path,\n",
    "                dcm_dir=temp_dir,\n",
    "            )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "493469b802c074bb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
