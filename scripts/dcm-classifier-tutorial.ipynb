{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03a1eaa4-2e9c-4eb2-b693-531f2d1fb7b8",
   "metadata": {},
   "source": [
    "# Tutorial dcm-classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e629a14-3040-4e91-8325-eaee8ec1352c",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "This tutorial is meant to show developers the process for altering the dcm-classifier package for developement with new DICOM data.\n",
    "\n",
    "## Setup\n",
    "\n",
    "If you have not already, clone the git hub repository by running the following in the terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0408159-2975-4ef2-85ed-34183fe7e798",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone git@github.com:BRAINSia/dcm-classifier.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c2fc1e-08ef-44d0-baa5-9825ee461327",
   "metadata": {},
   "source": [
    "Next, to install the necessary development packages, run the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185b4700-3466-407c-9837-7cefa3d71a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r ../requirements_dev.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb6a00d-1cdd-464d-8fab-d43ffe0e43c7",
   "metadata": {},
   "source": [
    "## Data Curation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52691ff0-dc1e-4083-86b8-05162e477320",
   "metadata": {},
   "source": [
    "### Field Sheet Creation\n",
    "\n",
    "The first step given a DICOM session directory, is to create a DICOM field sheet at a volume level with the images' associated file metadata. The `generate_dicom_dataframe` method can be called via basic function call as well as from command line. You are going to generate a small dataframe to display the functions output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a556a2-6cc7-4de1-b713-e834a799423d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from create_dicom_fields_sheet.py import *\n",
    "\n",
    "current_file_path: Path = Path(_file__).absolute()\n",
    "\n",
    "root_directory = current_file_path.parent.parent\n",
    "test_file = \"test_file.xlsx\"\n",
    "\n",
    "model: Path = root_directory / \"models\" / \"rf_classifier.onnx\"\n",
    "\n",
    "# make the inferer object\n",
    "inferer = ImageTypeClassifierBase(classification_model_filename=model)\n",
    "\n",
    "# make the DICOM field sheet\n",
    "generate_dicom_dataframe(session_dirs=root_directory / \"test\" / \"testing_data\" / \"anonymized_testing_data\" / \"anonymized_data\", output_file=\"./\" + test_file, inferer=inferer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e4304f-f003-4e39-894f-f79098fb4026",
   "metadata": {},
   "source": [
    "**Note:** The `create_dicom_fields.py` script can also be automated using the `run_all_dicom_data_sheets.sh` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06eba56-098d-4f6d-b921-ea0b9dcdf069",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 create_dicom_fields_sheet.py --dicom_path <path_to_dicom_session> --out <output_dicom_field_sheet>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34bab27-f7a1-4650-839f-a2e90c0a0ae0",
   "metadata": {},
   "source": [
    "### Field Sheet Combination\n",
    "\n",
    "If you are dealing with multiple field sheets, the `combine_excel_spreadsheets.py` script will combine the sheets into one big field sheet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab78bba-9e78-47dd-9077-2982ff12fad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from combine_excel_spreadsheets import get_all_column_names\n",
    "\n",
    "excel_files: list[Path] = [x for x in (\".\").glob(\"*.xls*\")]\n",
    "\n",
    "# create combined dataframe\n",
    "all_column_names: pd.DataFrame = get_all_column_names(excel_files)\n",
    "\n",
    "# save the combined frame to an excel file\n",
    "all_column_names.to_excel(\"./all_dicom_combined_data.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a3c206-07d2-404e-88e3-f7da7e330256",
   "metadata": {},
   "source": [
    "### Feature Creation\n",
    "\n",
    "Feature creation is a pertinent step which allows developers to choose the features used in the model. The `parse_useful_column_headers` method allows developers to choose features they believe will be useful to enter into the model.\n",
    "\n",
    "#### Header Dictionary\n",
    "\n",
    "A header dictionary is a spreadsheet with the fields taken from DICOM images. From these fields, you can select whether to keep them or remove them from the training file. You can do this by either setting the training flag to 1 to use in training, and any other number will not be included in the file. Also, you can choose the action for the header such as dropping the field \"drop\" and \"keep\" to keep the field. The header dictionary also allows for control over one hot encoding headers that contain arrays and strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6e79ca-c12d-4d56-b774-267d1e13bf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLE PIC OF HEADER DATA DICT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7592a3ba-5b6e-4c79-8138-a12948ec6068",
   "metadata": {},
   "source": [
    "### Running the Script\n",
    "\n",
    "In order to utilize the `parse_useful_column_headers` script, the header dictionary is needed for running this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47fc72a-3587-4bca-89d9-65a574052b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from parse_useful_column_headers import *\n",
    "\n",
    "tutorial_training_file = \"tutorial_training_file.xlsx\"\n",
    "\n",
    "# create the training file\n",
    "parse_column_headers(\n",
    "    header_data_df=clean_header_df,\n",
    "    input_file=test_file,\n",
    "    output_path=tutorial_training_file\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056e0ffb-603b-4563-9d8c-1e2d27f98265",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3225ac2c-a9a5-4b38-91e8-bf78ff1d7d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61761a88-0a40-4e31-bee1-e0ea832b341d",
   "metadata": {},
   "source": [
    "## Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2367aa6-8c27-470e-9c1d-d0d865f3146e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
